{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.layers import LSTM, Dense, SimpleRNN, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_emoji.csv',header=None)\n",
    "test = pd.read_csv('test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2 : \":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§\n",
      "1 ‚öæ\n",
      "2 üòÑ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "for ix in emoji_dict.keys():\n",
    "    print(ix,emoji.emojize(emoji_dict[ix], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train[0], train[1], test[0], test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132,), (132,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56,), (56,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent.split() for sent in X_train]\n",
    "X_test = [sent.split() for sent in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 0\n",
    "for sent in X_train:\n",
    "    maxLen = max(maxLen, len(sent))\n",
    "for sent in X_test:\n",
    "    maxLen = max(maxLen, len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train = np.zeros((len(X_train), 10, 50))\n",
    "embedding_matrix_test = np.zeros((len(X_test), 10, 50))\n",
    "\n",
    "for ix in range(len(X_train)):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(len(X_test)):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10, 128)           22912     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 56,453\n",
      "Trainable params: 56,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(SimpleRNN(128, input_shape=(10,50), return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(128, input_shape=(10,50), return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.0147 - acc: 0.1591\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 359us/step - loss: 1.6783 - acc: 0.2652\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 319us/step - loss: 1.4569 - acc: 0.3712\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 302us/step - loss: 1.5358 - acc: 0.3561\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 334us/step - loss: 1.2144 - acc: 0.5379\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 403us/step - loss: 1.1136 - acc: 0.5606\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 402us/step - loss: 1.0485 - acc: 0.5682\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 382us/step - loss: 0.8413 - acc: 0.6667\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 357us/step - loss: 0.7022 - acc: 0.7273\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 365us/step - loss: 0.6678 - acc: 0.7273\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 367us/step - loss: 0.5739 - acc: 0.7879\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 404us/step - loss: 0.5415 - acc: 0.8106\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 365us/step - loss: 0.5156 - acc: 0.8182\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 367us/step - loss: 0.4488 - acc: 0.8561\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 382us/step - loss: 0.3544 - acc: 0.8864\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 376us/step - loss: 0.3770 - acc: 0.8561\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 388us/step - loss: 0.3505 - acc: 0.8788\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 368us/step - loss: 0.2442 - acc: 0.9470\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 377us/step - loss: 0.1731 - acc: 0.9773\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 369us/step - loss: 0.1395 - acc: 0.9621\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 373us/step - loss: 0.1600 - acc: 0.9621\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 393us/step - loss: 0.1604 - acc: 0.9470\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 363us/step - loss: 0.1292 - acc: 0.9773\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 395us/step - loss: 0.1405 - acc: 0.9545\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 360us/step - loss: 0.1770 - acc: 0.9394\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 402us/step - loss: 0.1171 - acc: 0.9848\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 433us/step - loss: 0.0852 - acc: 0.9848\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 358us/step - loss: 0.0828 - acc: 0.9773\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 358us/step - loss: 0.0660 - acc: 0.9848\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 440us/step - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 353us/step - loss: 0.0475 - acc: 0.9924\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 362us/step - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 395us/step - loss: 0.0619 - acc: 0.9924\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 399us/step - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 343us/step - loss: 0.0512 - acc: 0.9924\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 381us/step - loss: 0.0863 - acc: 0.9697\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 393us/step - loss: 0.0683 - acc: 0.9773\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 401us/step - loss: 0.0725 - acc: 0.9848\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 385us/step - loss: 0.1016 - acc: 0.9697\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 378us/step - loss: 0.0781 - acc: 0.9924\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 394us/step - loss: 0.1017 - acc: 0.9773\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 365us/step - loss: 0.0597 - acc: 0.9924\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 385us/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 397us/step - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 410us/step - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 377us/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 394us/step - loss: 0.0510 - acc: 0.9924\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 366us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 395us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 369us/step - loss: 0.0172 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126a83400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(embedding_matrix_train, Y_train, epochs=50, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535714285714286\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_preds == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5887 - acc: 0.2803\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 771us/step - loss: 1.5304 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 769us/step - loss: 1.4688 - acc: 0.3636\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 766us/step - loss: 1.3927 - acc: 0.4848\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 850us/step - loss: 1.3446 - acc: 0.4924\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 760us/step - loss: 1.1834 - acc: 0.6439\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 872us/step - loss: 1.0429 - acc: 0.6212\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 948us/step - loss: 0.9253 - acc: 0.6212\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8047 - acc: 0.7045\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6165 - acc: 0.7652\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6320 - acc: 0.7727\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5399 - acc: 0.7879\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5622 - acc: 0.8258\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6457 - acc: 0.7424\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6776 - acc: 0.7348\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5154 - acc: 0.7652\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5135 - acc: 0.7955\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 981us/step - loss: 0.4733 - acc: 0.8258\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 998us/step - loss: 0.4016 - acc: 0.8712\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 894us/step - loss: 0.3434 - acc: 0.8864\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 904us/step - loss: 0.3144 - acc: 0.8636\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 925us/step - loss: 0.2673 - acc: 0.8939\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 965us/step - loss: 0.2983 - acc: 0.8939\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 987us/step - loss: 0.2310 - acc: 0.9091\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2834 - acc: 0.9167\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2174 - acc: 0.9015\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 938us/step - loss: 0.1714 - acc: 0.9545\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1253 - acc: 0.9697\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 900us/step - loss: 0.1455 - acc: 0.9621\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 808us/step - loss: 0.1025 - acc: 0.9773\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0995 - acc: 0.9697\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1120 - acc: 0.9545\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9394\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9545\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 951us/step - loss: 0.1194 - acc: 0.9470\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1640 - acc: 0.9470\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0753 - acc: 0.9773\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9773\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1024 - acc: 0.9621\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9697\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0666 - acc: 0.9773\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 977us/step - loss: 0.1150 - acc: 0.9621\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 875us/step - loss: 0.0426 - acc: 0.9848\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 880us/step - loss: 0.0755 - acc: 0.9697\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0997 - acc: 0.9621\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0316 - acc: 0.9924\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 925us/step - loss: 0.0350 - acc: 0.9848\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 847us/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 878us/step - loss: 0.0605 - acc: 0.9773\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0733 - acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126ad16a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(embedding_matrix_train, Y_train, epochs=50, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607142857142857\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_preds == Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
